
<!-- saved from url=(0030)http://wangzheallen.github.io/ -->
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
	
	<title>Wang Wentao</title>
  <link rel="shortcut icon" href="http://wangzheallen.github.io/logo.jpg">
	<meta content="Yue Zhou, zytx121.github.io/" name="keywords">
	<style media="screen" type="text/css">html, body, div, span, applet, object, iframe, h1, h2, h3, h4, h5, h6, p, blockquote, pre, a, abbr, acronym, address, big, cite, code, del, dfn, em, font, img, ins, kbd, q, s, samp, small, strike, strong, sub, tt, var, dl, dt, dd, ol, ul, li, fieldset, form, label, legend, table, caption, tbody, tfoot, thead, tr, th, td {
  border: 0pt none;
  font-family: inherit;
  font-size: 100%;
  font-style: inherit;
  font-weight: inherit;
  margin: 0pt;
  outline-color: invert;
  outline-style: none;
  outline-width: 0pt;
  padding: 0pt;
  vertical-align: baseline;
}

a {
  color: #1772d0;
  text-decoration:none;
}

a:focus, a:hover {
  color: #f09228;
  text-decoration:none;
}

a.paper {
  font-weight: bold;
  font-size: 12pt;
}

b.paper {
  font-weight: bold;
  font-size: 12pt;
}

* {
  margin: 0pt;
  padding: 0pt;
}

body {
  position: relative;
  margin: 3em auto 2em auto;
  width: 850px;
  font-family: Lato, Verdana, Helvetica, sans-serif;
  font-size: 14px;
  background: #eee;
}

h2 {
  font-family: Lato, Verdana, Helvetica, sans-serif;
  font-size: 15pt;
  font-weight: 700;
}

h3 {
  font-family: Lato, Verdana, Helvetica, sans-serif;
  font-size: 16px;
  font-weight: 700;
}

strong {
  font-family: Lato, Verdana, Helvetica, sans-serif;
  font-size: 13px;
  font-weight:bold;
}

ul {
  list-style: circle;
}

img {
  border: none;
}

li {
  padding-bottom: 0.5em;
  margin-left: 1.4em;
}

alert {
  font-family: Lato, Verdana, Helvetica, sans-serif;
  font-size: 13px;
  font-weight: bold;
  color: #FF0000;
}

em, i {
	font-style:italic;
}

div.section {
  clear: both;
  margin-bottom: 1.5em;
  background: #eee;
}

div.spanner {
  clear: both;
}

div.paper {
  clear: both;
  margin-top: 0.4em;
  margin-bottom: 0.7em;
  border: 0px solid #ddd;
  background: #fff;
  padding: 0.55em .8em 0.6em .8em;
  border-top-right-radius:10px; 
  border-top-left-radius:10px; 
  border-bottom-left-radius:10px; 
  border-bottom-right-radius:10px;
  line-height: 140%;
}

div.paper div {
  padding-left: 230px;
}

img.paper {
  margin-bottom: 0.5em;
  float: left;
  width: 200px;
}

span.blurb {
  font-style:italic;
  display:block;
  margin-top:0.75em;
  margin-bottom:0.5em;
}

pre, code {
  font-family: Open Sans Light, Helvetica, sans-serif;
  font-size: 13px;
  margin: 1em 0;
  padding: 0;
}

div.paper pre {
  font-size: 0.9em;
}
</style>

<link href="./zy/css" rel="stylesheet" type="text/css"><!--<link href='http://fonts.googleapis.com/css?family=Open+Sans+Condensed:300' rel='stylesheet' type='text/css'>--><!--<link href='http://fonts.googleapis.com/css?family=Open+Sans' rel='stylesheet' type='text/css'>--><!--<link href='http://fonts.googleapis.com/css?family=Yanone+Kaffeesatz' rel='stylesheet' type='text/css'>-->
<script async="" src="./zy/analytics.js"></script><script async="" src="./zy/analytics.js"></script><script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-45959174-3', 'zytx121.github.io');
  ga('send', 'pageview');

</script><script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-66888300-1', 'auto');
  ga('send', 'pageview');


</script><script type="text/javascript" src="./zy/hidebib.js"></script><script src="./zy/main.js"></script><script type="text/javascript" src="./zy/jquery-1.12.4.min.js"></script></head>





<!--
<body>
<div style="margin-bottom: 1em; border: 1px solid #ddd; background-color: #fff; padding: 1em; height: 140px;">
<div style="margin: 0px auto; width: 100%;">
<img title="Zhewang" style="float: left; padding-left: .01em; height: 140px;" src="homepage.png" />
<div style="padding-left: 10em; vertical-align: top; height: 120px;"><span style="line-height: 150%; font-size: 20pt;">Zhe Wang</span><br />
<span><a href='http://vision.ics.uci.edu/'>Computational Vision Group</a></span> <br />
<span>Univerity of California, Irvine</span><br />
<span><strong>Email  </strong>: buptwangzhe2012 [at] gmail [dot] com</span> <br />
</div>
</div>
</div>
-->

<body>
<div style="margin-bottom: 1em; border-top-right-radius:10px; border-top-left-radius:10px; border-bottom-left-radius:10px; border-bottom-right-radius:10px; border: 0px solid #ddd; background-color: #fff; padding: 1em; height: 140px;">
<div style="margin: 0px auto; width: 100%;">
  <img title="Yue Zhou" style="float: left; padding-left: .3em; padding-top: 0em; height: 140px;" src="./zy/homepage.png">
  <div style="padding-left: 12em; padding-top: 0em; vertical-align: top; height: 120px; width: 100%;">
    <p>&nbsp;</p>
    <p><span style="line-height: 80%; font-size: 16pt;">Yue Zhou</span></p>
    <p>&nbsp;</p>
    <!--<p><a href="https://scholar.google.com/citations?user=FL-t3JEAAAAJ&hl=en">Google Scholar</a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://github.com/wangzheallen">Github</a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://www.linkedin.com/in/zhe-wang-8204927a/">LinkedIn</a></p> -->
    <p>Email: sjtu_zy[at]sjtu[dot]edu[dot]cn </p>
    <p>Department of Electronic Engineering</p>
    <p>Shanghai Jiao Tong University, Shanghai, China 200240</p>
    <p>&nbsp;</p>
    <p>
    <a href="https://scholar.google.com.hk/citations?user=CX-o0V4AAAAJ&hl=zh-CN" target="_blank"><img class="responsive-img social-photo " style="float: left; padding-left: 0.3em; padding-top: 0em; height: 30px; " src="./zy/google_color1.png"></a> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
    <!-- <a href="https://www.linkedin.com/in/zhe-wang-8204927a/" target="_blank"><img class="responsive-img social-photo " style="float: left; padding-left: .3em; padding-top: 0em; height: 30px; " src="./zy/linkedin_blue.png"></a> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
    <a href="https://github.com/wangzheallen" target="_blank"><img class="responsive-img social-photo " style="float: left; padding-left: .3em; padding-top: 0em; height: 30px; " src="./zy/github_color.png"></a> -->
    </p>
</div>
</div>
</div>
<!--<div style="clear: both; background-color: #fff; margin-top: 1.5em; padding: .2em; padding-left: .3em;">-->

<div style="clear: both;">
<div class="section">
<h2>About Me 
 <!-- (<a href=''>CV</a>) (<a href='https://scholar.google.com.hk/citations?user=FL-t3JEAAAAJ&hl=en'>Google Scholar</a>) -->
</h2>
<div class="paper">

I am currently a Ph.D. student in <a href="http://www.cs.sjtu.edu.cn/"> Department of Electronic Engineering, Shanghai Jiao Tong University</a>. My research advisors are <a href="https://sp.sjtu.edu.cn/">Prof. Xue Jiang</a> and <a href="https://wnt.sjtu.edu.cn/sps/teacher.html/"> Prof. Xingzhao Liu</a>.

<br> <br>

I received the B. E. degree from Electronic and Information Engineering, <a href="https://www.bupt.edu.cn/">Beijing University of Posts and Telecommunications</a>, Beijing, China, in 2017.

<br> <br>

My research interests include deep learning and computer vision, especially focusing on <strong>rotated object detection</strong> and <strong>Ship detection</strong>.

<br><br>

<strong> <p style="color:red">I am seeking a full-time research / applied research job on computer vision. </p></strong>


</div>
</div>
</div>

<div style="clear: both;">
<div class="section">
  <h2>News</h2>
  <div class="paper">
    <ul>
    <li> August 2022: One collaborative paper on Rotation Detection is accepted by TPAMI.</li>
    <!-- <li> March 2022: One paper on Image Inpainting is accepted by CVPR 2022.</li> -->
    <!-- <li> January 2022: Research internship at <a href="https://open.youtu.qq.com/#/open">Tencent YouTu Lab</a>, Shanghai, working with <a href="https://scholar.google.com.hk/citations?user=xMpvoLMAAAAJ&hl=zh-CN">Shen Chen</a> and <a href="https://scholar.google.com.hk/citations?hl=zh-CN&user=qkpaPuAAAAAJ">Taiping Yao</a>.</li> -->
    <!-- <li> September 2021: One collaborative paper on Rotation Detection is accepted by NeurIPS 2021.</li> -->
    <!-- <li> July 2021: One paper on Image Inpainting is accepted by ICCV 2021.</li> -->
    <!-- <li> July 2021: One paper on Video Semantic Segmentation is accepted by ACM MM 2021.</li> -->
    <!-- <li> May 2021: One collaborative paper on Rotation Detection is accepted by ICML 2021.</li> -->
    <li> March 2021: One collaborative paper on Rotation Detection is accepted by CVPR 2021.</li>
    <li> September 2020: I'm joining Department of EE at Shanghai Jiao Tong University as a Ph.D. student.</li>
    <!-- <li> June 2020: One collaborative paper on Image Inpainting is accepted by IEEE SPL.</li> -->
    <li> September 2018: I'm joining Department of EE at Shanghai Jiao Tong University as a M.S. student.</li>
    </ul>
  </div>
</div>
</div>

<div style="clear: both;">
<div class="section">
<h2 id="confpapers">Selected Publications </h2> 
</div>


<!-- <div class="paper" id="TAS"><img class="paper" src="./zy/cvpr22_Inp.png" title="Dual-path Image Inpainting with Auxiliary GAN Inversion">
<div> <strong>Dual-path Image Inpainting with Auxiliary GAN Inversion
</strong><br>
<strong>Yue Zhou</strong>, Li Niu, Jianfu Zhang, Xue Yang, Liqing Zhang<br>
IEEE Conference on Computer Vision and Pattern Recognition (<strong>CVPR, CCF A</strong>), 2022<br>
[<a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Dual-Path_Image_Inpainting_With_Auxiliary_GAN_Inversion_CVPR_2022_paper.pdf">Paper</a>]  
[<a href="./zy/files/cvpr22_inp_slides.pdf">Slides</a>]
[<a href="./zy/files/cvpr22_inp_poster.pdf">Poster</a>]  
<br>
</div>
<div class="spanner"></div>
</div> -->



<!-- <div class="paper" id="TAS"><img class="paper" src="./zy/kld.png" title="Learning High-Precision Bounding Box for Rotated Object Detection via Kullback-Leibler Divergence">
<div> <strong>Learning High-Precision Bounding Box for Rotated Object Detection via Kullback-Leibler Divergence
</strong><br>
Xue Yang, Xiaojiang Yang, Jirui Yang, Qi Ming, <strong>Yue Zhou</strong>, Qi Tian, Junchi Yan<br>
Advances in Neural Information Processing Systems (<strong>NeurIPS, CCF A</strong>), 2021<br>
[<a href="https://arxiv.org/abs/2106.01883">Paper</a>]   
[<a href="https://github.com/yangxue0827/RotationDetection">Github</a>]  
[<a href="./zy/files/kld_slides.pdf">Slides</a>]
[<a href="./zy/files/neurips21_yx_poster.pdf">Poster</a>]  
<br>
</div>
<div class="spanner"></div>
</div> -->


<!-- <div class="paper" id="TAS"><img class="paper" src="./zy/gwd.png" title="Rethinking Rotated Object Detection with Gaussian Wasserstein Distance Loss">
<div> <strong>Rethinking Rotated Object Detection with Gaussian Wasserstein Distance Loss
</strong><br>
Xue Yang, Junchi Yan, Qi Ming, <strong>Yue Zhou</strong>, Xiaopeng Zhang, Qi Tian<br>
International Conference on Machine Learning (<strong>ICML, CCF A</strong>), 2021<br>
[<a href="https://arxiv.org/abs/2101.11952">Paper</a>]   
[<a href="https://github.com/yangxue0827/RotationDetection">Github</a>]  
[<a href="./zy/files/gwd_slides.pdf">Slides</a>]
[<a href="./zy/files/icml21_yx_poster.pdf">Poster</a>]  
  <br>
</div>
<div class="spanner"></div>
</div>
 -->
<div class="paper" id="TAS"><img class="paper" src="./zy/dcl.png" title="Dense Label Encoding for Boundary Discontinuity Free Rotation Detection">
<div> <strong>Dense Label Encoding for Boundary Discontinuity Free Rotation Detection
</strong><br>
Xue Yang, Liping Hou, <strong>Yue Zhou</strong>, Wentao Wang, Junchi Yan<br>
IEEE Conference on Computer Vision and Pattern Recognition (<strong>CVPR, CCF A</strong>), 2021<br>
[<a href="https://arxiv.org/abs/2011.09670">Paper</a>]   
[<a href="https://github.com/yangxue0827/RotationDetection">Github</a>]  
[<a href="./zy/files/dcl_slides.pdf">Slides</a>]
[<a href="./zy/files/cvpr21_yx_poster.pdf">Poster</a>]  
  <br>
</div>
<div class="spanner"></div>
</div>


<!-- <div class="paper" id="TAS"><img class="paper" src="./zy/iccv21_Inp.png" title="Parallel Multi-Resolution Fusion Network for Image Inpainting">
<div> <strong>Parallel Multi-Resolution Fusion Network for Image Inpainting
</strong><br>
<strong>Yue Zhou*</strong>, Jianfu Zhang*, Li Niu, Haoyu Ling, Xue Yang, Liqing Zhang<br>
IEEE International Conference on Computer Vision (<strong>ICCV, CCF A</strong>), 2021<br>
[<a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Wang_Parallel_Multi-Resolution_Fusion_Network_for_Image_Inpainting_ICCV_2021_paper.pdf">Paper</a>] 
[<a href="./zy/files/cvpr22_inp_slides.pdf">Slides</a>]
[<a href="./zy/files/cvpr22_inp_poster.pdf">Poster</a>]  
<br>
</div>
<div class="spanner"></div>
</div> -->


<!-- <div class="paper" id="TAS"><img class="paper" src="./zy/mm21_vss.png" title="Video Semantic Segmentation via Sparse Temporal Transformer">
<div> <strong>Video Semantic Segmentation via Sparse Temporal Transformer
</strong><br>
<strong>Yue Zhou*</strong>, Jiangtong Li*, Junjie Chen, Li Niu, Jianlou Si, Chen Qian, Liqing Zhang<br>
ACM International Conference on Multimedia  (<strong>ACM MM, CCF A, Oral</strong>), 2021<br>
[<a href="https://dl.acm.org/doi/pdf/10.1145/3474085.3475409">Paper</a>] 
[<a href="./zy/files/mm21_vss_slides.pdf">Slides</a>]
[<a href="./zy/files/mm21_vss_poster.pdf">Poster</a>]  
<br>
</div>
<div class="spanner"></div>
</div> -->



<!-- <div class="paper" id="TAS"><img class="paper" src="./zy/spl_Inp.png" title="Image Editing via Segmentation Guided Self-Attention Network">
<div> <strong>Image Editing via Segmentation Guided Self-Attention Network
</strong><br>
Jianfu Zhang, Peiming Yang, <strong>Yue Zhou</strong>, Yan Hong, Liqing Zhang<br>
IEEE Signal Processing Letters (<strong>SPL, CCF C</strong>), 2020<br>
[<a href="https://ieeexplore.ieee.org/abstract/document/9195134">Paper</a>] 
<br>
</div>
<div class="spanner"></div>
</div> -->


<!-- <div style="clear: both;">
<div class="section">
<h2 id="confpapers">Academic Service</h2>
<div class="paper">
<ul>
<strong>Journal Reviewer</strong> <br>
<p> IEEE TCSVT</p>
<br>
<strong>Conference Reviewer</strong> <br>
<p> AAAI 2023, ICML 2022, NeurIPS 2022, CVPR 2022, MLSP 2021</p>
</ul>
<div class="spanner"></div>
</div>
</div>
</div> -->



<!-- <div style="clear:both;">
  <p align="right"><font size="5">Published with <a href="https://pages.github.com/">GitHub Pages</a></font></p>
  </div> -->

<footer class="page-footer grey lighten-2">
  <div class="row">
    <div class="widgetContainer" style="width:300px; margin: 0 auto;">        
      <script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=bbD4sDviSWDU3eM7DQwrQNxTVgSEpCJ8tZozM9hXEUI&cl=ffffff&w=a"></script>
    </div>
  </div>
  <div class="footer-copyright center black-text">
    Copyright © Yue Zhou 2023
  </div>  
</footer>


<!-- This site has been visisted <a href="https://www.easycounter.com/">
<img src="./zy/counter.php" border="0" alt="page counter"></a><a href="https://www.easycounter.com/"></a> times in total. -->



<hr>


<div class="jvectormap-tip"></div></body></html>